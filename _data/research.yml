- title: Examples and concepts from complementary encodings
  id: complementary
  image: "/media/research-complementary.png"
  text:
    - The hippocampal region CA3 is believed to produce memories from incoming sensory information. Before arriving at CA3, this information stream is split along two neural pathways with different encoding properties&mdash;one is more correlated than the other. We construct a model of CA3 that incorporates this architecture to investigate its computational purpose. Our model reveals that decorrelated encodings maintain distinctions between similar experiences, whereas correlated encodings build concepts from them. This explains how the hippocampus forms distinct memories for separate visits with your grandmother while integrating them through &ldquo;grandmother cells&rdquo; that respond to many different forms of her.
    - Our model proposes that example-like and concept-like encodings are accessed at different phases of the theta oscillation, which is a dominant brain rhythm in the hippocampus. Its predictions stand up to extensive experimental tests using publicly available neural recordings. Finally, we extend our insights from the hippocampus to machine learning by introducing a novel HalfCorr loss function that endows neural networks with CA3-like complementary encodings. HalfCorr networks outperform networks with only single encoding types in a multitask learning paradigm, demonstrating how computational advantages found within neural systems can be unlocked through bio-inspired artificial intelligence.
  refs:
    - citation: Kang L &amp; Toyoizumi T. Distinguishing examples while building concepts in hippocampal and artificial networks. <i>bioRxiv</i> (2023).
      link: "https://www.biorxiv.org/content/10.1101/2023.02.21.529365"
    - citation: Kang L &amp; Toyoizumi T. Hopfield-like model with complementary encodings of memories. <i>Phys Rev E</i> 108, 054410 (2023).
      link: "https://journals.aps.org/pre/abstract/10.1103/PhysRevE.108.054410"
      pdf: "/docs/kang2023hopfield.pdf"


- title: Noise resilience in continuous attractor networks
  id: bumps
  mp4: "/media/research-bumps.mp4"
  text:
    - Our brains maintain internal representations of values related to the external world, which allows us to, for example, find our way to the door if the lights go off. Continuous attractor networks are one class of neural circuit used to accomplish this. They contain localized regions of activity, called attractor bumps, whose positions can encode the value of a continuous variable. However, the brain is teeming with biological noise that perturbs the positions of the bumps and compromises the accuracy of the network.
    - We uncover a new means through which continuous attractor networks can enhance their robustness to noise. They can distribute their activity across multiple attractor bumps instead of concentrating it within a single bump. While such configurations have been considered by researchers, the connection between bump number and noise resilience had not been appreciated. This observation contributes to our fundamental knowledge of attractor networks, and it may help to explain why the mammalian grid cell network appears to have evolved a multi-bump configuration.
  refs:
    - citation: Wang R &amp; Kang L. Multiple bumps can enhance robustness to noise in continuous attractor networks. <i>PLOS Comput Biol</i> 18, e1010547 (2022).
      link: "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010547"
      pdf: "/docs/wang2022bumps.pdf"

- title: Topological data analysis for neuroscience
  id: cohomology
  image: "/media/research-cohomology.png"
  text:
    - To operate effectively, the enormous number of neurons in brain circuits must coordinate their activity. Detecting signatures of coordination in large, complex sets of neural data may help us understand neural computation. One such signature is topological structure, such as loops and voids, formed by the data in high-dimensional phase space.
    - Persistent cohomology is a powerful technique for discovering topological structure in data. Strategies for its use in neuroscience are still undergoing development. We explore the application of persistent cohomology to the brainâ€™s spatial representation system. Our results suggest guidelines for applying persistent cohomology to experimental neural recordings.
  refs:
    - citation: Kang L, Xu B &amp; Morozov D. Evaluating state space discovery by persistent cohomology in the spatial representation system. <i>Front Comput Neurosci</i> 15, 616748 (2021).
      link: "https://www.frontiersin.org/articles/10.3389/fncom.2021.616748"
      pdf: "/docs/kang2021cohomology.pdf"

- title: Grid cell organization and dynamics
  id: replay
  mp4: "/media/research-replay.mp4"
  text:
    - The entorhinal cortex (EC) contains grid cells, each of which only fires when we approach certain locations that form a triangular lattice in space. There is experimental evidence that the grid cell network can be modeled as a continuous attractor, in which neural activity evolves through a set of attractor states that represent different positions in the 2D environment.
    - However, existing attractor models did not capture several key phenomena exhibited by the grid system. Grid cells belong to modules, which suggests that spatial information is discretized in memories, and grid cells can fire in rapid sequences that may be related to memory consolidation or planning. Through simulations, we demonstrated how these phenomena arise in continuous attractors with the addition of experimentally observed or biologically plausible features of EC. Our results suggest mechanisms through which the hippocampal region performs memory-related computations.
  refs:
    - citation: Kang L &amp; Balasubramanian V. A geometric attractor mechanism for self-organization of entorhinal grid modules. <i>eLife</i> 8, e46687 (2019).
      link: "https://elifesciences.org/articles/46687"
      pdf: "/docs/kang2019modules.pdf"
    - citation: Kang L &amp; DeWeese MR. Replay as wavefronts and theta sequences as bump oscillations in a grid cell attractor network. <i>eLife</i> 8, e46351 (2019).
      link: "https://elifesciences.org/articles/46351"
      pdf: "/docs/kang2019replay.pdf"

